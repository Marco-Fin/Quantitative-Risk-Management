{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation: Normal\n",
    "\n",
    "Parameter estimation is the strongest method of VaR estimation because it assumes that the loss distribution class is known. Parameters are estimated to fit data to this distribution, and statistical inference is then made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols       Citibank  Morgan Stanley  Goldman Sachs  J.P. Morgan\n",
      "Date                                                              \n",
      "2004-12-31  481.799988       55.520000     104.040001    39.009998\n",
      "2005-01-03  482.700012       55.900002     104.949997    39.150002\n",
      "2005-01-04  478.600006       55.299999     104.269997    38.410000\n",
      "2005-01-05  484.600006       54.980000     103.800003    38.490002\n",
      "2005-01-06  489.299988       56.279999     105.230003    38.709999\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas_datareader import DataReader\n",
    "from datetime import datetime\n",
    "\n",
    "stocklist = ['C', 'MS', 'GS', 'JPM']\n",
    "\n",
    "start = datetime(2004,12,31)\n",
    "end = datetime(2010,12,31)\n",
    "\n",
    "portfolio = DataReader(stocklist, 'yahoo',start, end)['Close']\n",
    "portfolio.rename(columns={'C':'Citibank', 'MS':'Morgan Stanley','GS':'Goldman Sachs','JPM':'J.P. Morgan'}, inplace=True)\n",
    "print(portfolio.head())\n",
    "\n",
    "weights = [0.25, 0.25, 0.25, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the portfolio's daily returns\n",
    "portfolio_returns = portfolio.pct_change().dot(weights).dropna()\n",
    "\n",
    "# Compute the portfolio's daily losses\n",
    "portfolio_losses = -portfolio_returns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR_95, Normal distribution:  0.053938106880521725\n",
      "Anderson-Darling test result:  AndersonResult(statistic=86.57275579677253, critical_values=array([0.574, 0.654, 0.785, 0.916, 1.089]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]))\n"
     ]
    }
   ],
   "source": [
    "# Import the Normal distribution and skewness test from scipy.stats\n",
    "from scipy.stats import norm, anderson\n",
    "\n",
    "# Fit portfolio losses to the Normal distribution\n",
    "params = norm.fit(portfolio_losses)\n",
    "\n",
    "# Compute the 95% VaR from the fitted distribution, using parameter estimates\n",
    "VaR_95 = norm.ppf(0.95, *params)\n",
    "print(\"VaR_95, Normal distribution: \", VaR_95)\n",
    "\n",
    "# Test the data for Normality\n",
    "print(\"Anderson-Darling test result: \", anderson(portfolio_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter estimation: Skewed Normal\n",
    "\n",
    "We'll parametrically estimate the 95% VaR of a loss distribution fit. This is a more general distribution than the Normal and allows losses to be non-symmetrically distributed. We might expect losses to be skewed during the crisis, when portfolio losses were more likely than gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewtest result:  SkewtestResult(statistic=-9.46377341649772, pvalue=2.9702650510105885e-21)\n",
      "VaR_95 from skew-normal:  0.07953135436049741\n"
     ]
    }
   ],
   "source": [
    "# Import the skew-normal distribution and skewness test from scipy.stats\n",
    "from scipy.stats import skewnorm, skewtest\n",
    "\n",
    "# Fit the Student's t distribution to crisis losses\n",
    "crisis_losses = portfolio_losses.loc['2008-01-01':'2009-12-31']\n",
    "\n",
    "# Test the data for skewness\n",
    "print(\"Skewtest result: \", skewtest(crisis_losses))\n",
    "\n",
    "# Fit the portfolio loss data to the skew-normal distribution\n",
    "params = skewnorm.fit(crisis_losses)\n",
    "\n",
    "# Compute the 95% VaR from the fitted distribution, using parameter estimates\n",
    "VaR_95 = skewnorm.ppf(0.95, *params)\n",
    "print(\"VaR_95 from skew-normal: \", VaR_95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Anderson-Darling and skewtest results show the Normal distribution estimates cannot be relied upon. Skewness matters for loss distributions, and parameter estimation is one way to quantify this important feature of the financial crisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Simulation\n",
    "\n",
    "\n",
    "Historical simulation of VaR assumes that the distribution of historical losses is the same as the distribution of future losses. We'll test if this is true for our investment bank portfolio by comparing the 95% VaR from 2005 - 2006 to the 95% VaR from 2007 - 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR_95, 2005-2006:  0.01470023008198797 ; VaR_95, 2007-2009:  0.05492612537506693\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "asset_returns_list = [portfolio['2005-01-01':'2006-12-31'].pct_change().dropna(), portfolio['2007-01-01':'2008-12-31'].pct_change().dropna()]\n",
    "\n",
    "# Create portfolio returns for the two sub-periods using the list of asset returns\n",
    "portfolio_returns_list = np.array([ x.dot(weights) for x in asset_returns_list])\n",
    "\n",
    "# Derive portfolio losses from portfolio returns\n",
    "losses = - portfolio_returns_list\n",
    "\n",
    "# Find the historical simulated VaR estimates\n",
    "VaR_95 = [np.quantile(x, 0.95) for x in losses]\n",
    "\n",
    "# Display the VaR estimates\n",
    "print(\"VaR_95, 2005-2006: \", VaR_95[0], '; VaR_95, 2007-2009: ', VaR_95[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VaR estimates are very different for the two time periods. This indicates that over the entire 2005 - 2009 period the loss distribution was likely not stationary. Historical simulation, while very general, should be used with caution when the data is not from a stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Simulation\n",
    "\n",
    "We can use Monte Carlo simulation of the 2005-2010 investment bank portfolio assets to find the 95% VaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "\n",
    "# Create the CovarianceShrinkage instance variable\n",
    "cs = CovarianceShrinkage(portfolio)\n",
    "\n",
    "# Compute the efficient covariance matrix of returns\n",
    "e_cov = cs.ledoit_wolf()/252\n",
    "e_cov = e_cov.to_numpy()\n",
    "\n",
    "# Compute the mean and volatility\n",
    "mu = np.array(-portfolio.pct_change().dropna().mean()).reshape((4,1))\n",
    "sigma = np.array(-portfolio.pct_change().dropna().std()).reshape((4,1))\n",
    "\n",
    "total_steps = 1440\n",
    "N = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo VaR_95 estimate:  0.0031957613854370058\n"
     ]
    }
   ],
   "source": [
    "# Initialize daily cumulative loss for the assets, across N runs\n",
    "daily_loss = np.zeros((4,N))\n",
    "\n",
    "# Create the Monte Carlo simulations for N runs\n",
    "for n in range(N):\n",
    "    # Compute simulated path of length total_steps for correlated returns\n",
    "    correlated_randomness = e_cov @ norm.rvs(size = (4,total_steps))\n",
    "    # Adjust simulated path by total_steps and mean of portfolio losses\n",
    "    steps = 1/total_steps\n",
    "    minute_losses = mu * steps + correlated_randomness * np.sqrt(steps)\n",
    "    daily_loss[:, n] = minute_losses.sum(axis=1)\n",
    "    \n",
    "# Generate the 95% VaR estimate\n",
    "losses = weights @ daily_loss\n",
    "print(\"Monte Carlo VaR_95 estimate: \", np.quantile(losses, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've shown how Monte Carlo simulation can be used to create an entire range of possible outcomes when the underlying risk factor distributions are known. The resulting riskiness of the loss distribution can then be assessed using the VaR estimate, or a more complicated estimate such as CVaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
